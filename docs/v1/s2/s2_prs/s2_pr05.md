# PR-05 — Image Proxy Endpoint + SSRF Protections + Caching (L3 Spec)

This PR implements the **image proxy** required by Slice 2 to safely render external images embedded in web articles.  
It completes the sanitization pipeline introduced in PR-04 by making rewritten `<img src>` URLs resolvable.

This spec is binding and must conform to:
- L0 Constitution
- L1 Slice Roadmap
- Slice 2 (L2) Spec
- Slice 2 PR Roadmap (L3)

---

## 1. Goal

Provide a secure, authenticated backend image proxy that:
- Prevents SSRF and internal network access
- Validates image content (type, size, dimensions)
- Serves images efficiently with caching
- Integrates cleanly with the HTML sanitizer

---

## 2. Non-Goals

This PR explicitly does NOT include:
- Persistent cache (Redis, disk, or object storage)
- Media-level authorization checks (beyond auth)
- SVG sanitization or transformation
- Image resizing, optimization, or format conversion
- Public (unauthenticated) access

---

## 3. API Surface

### 3.1 Endpoint

```
GET /media/image?url=<encoded_url>
```

**Route definition** (existing routes use `@router.get("/media/{id}")` pattern):
```python
# In python/nexus/api/routes/media.py
@router.get("/media/image")
def get_proxied_image(
    url: str,
    viewer: Annotated[Viewer, Depends(get_viewer)],
) -> Response:
    ...
```

**Authentication (required):**
- `Authorization: Bearer <supabase_access_token>`
- `x-nexus-internal: <NEXUS_INTERNAL_SECRET>` (if enabled in env)

**Middleware enforcement:** This endpoint runs under the same FastAPI app/middleware stack that enforces auth globally. The `AuthMiddleware` handles both JWT verification and internal header checks (when `requires_internal_header=True` in staging/prod). No special per-route auth logic needed.

**Visibility:**
- Endpoint is authenticated-only
- No attempt is made to check which media references the image
- This is acceptable because:
  - The URL is only emitted inside already-authorized document HTML
  - The proxy itself must not become a public fetcher

---

## 4. Error Semantics

### 4.1 Error Codes

Extend `python/nexus/errors.py` with:

| Error Code | HTTP | Meaning |
|-----------|------|---------|
| `E_SSRF_BLOCKED` | 403 | URL violates SSRF rules (private IP, bad scheme, etc.) |
| `E_IMAGE_FETCH_FAILED` | 502 | Upstream fetch failed |
| `E_INGEST_TIMEOUT` | 504 | Upstream fetch timed out |
| `E_IMAGE_TOO_LARGE` | 413 | Image exceeds size or dimension limits |
| `E_INVALID_REQUEST` | 400 | Malformed URL or not a valid image |

Notes:
- Reuse `E_INGEST_TIMEOUT` for consistency with other upstream fetches
- Use `E_IMAGE_TOO_LARGE` for policy violations (>10MB, dimensions too large, decompression bomb)
- Do NOT leak details of blocked internal hosts in error messages
- **Verify:** `ApiError` supports arbitrary HTTP status codes including 413. Add test confirming response status is 413 with code `E_IMAGE_TOO_LARGE`

---

## 5. SSRF Protection Rules (Hard Constraints)

All of the following MUST pass, in order.

### 5.1 URL Parsing + Normalization

- Parse via `urllib.parse.urlparse`
- Reject if:
  - Scheme is not `http` or `https`
  - Host is empty
  - URL contains userinfo — check: `parsed.username is not None or parsed.password is not None or '@' in parsed.netloc`
  - Port is specified and not 80 or 443

**URL parameter:** The `url` query parameter MUST be percent-encoded. Document this and use `params={"url": ...}` in tests so httpx encodes properly.

**Normalized URL** (used for cache key, logging, ETag):
```python
def normalize_image_url(url: str) -> str:
    parsed = urlparse(url)
    # Lowercase scheme and host
    scheme = parsed.scheme.lower()
    host = parsed.hostname.lower()
    # Remove default ports
    port = parsed.port
    if port == 80 and scheme == "http":
        port = None
    if port == 443 and scheme == "https":
        port = None
    netloc = host if port is None else f"{host}:{port}"
    # Strip fragment, preserve query
    return urlunparse((scheme, netloc, parsed.path, parsed.params, parsed.query, ""))
```

- Cache key = `normalized_url` (not raw input)
- All validation uses normalized form

### 5.2 Hostname Denylist (Pre-DNS)

Before DNS resolution, reject hostnames matching:
- `localhost`
- Suffix `.local`
- Suffix `.internal`
- Suffix `.lan`
- Suffix `.home`

This prevents leaking "blocked internal host" errors and is good hygiene.

### 5.3 DNS Resolution (Validation Only)

- Resolve hostname via `socket.getaddrinfo`
- Collect **all** resolved IPs (IPv4 + IPv6)
- Reject if **any** resolved IP is:
  - Loopback (`127.0.0.0/8`, `::1`)
  - Private (`10/8`, `172.16/12`, `192.168/16`)
  - Link-local (`169.254/16`, `fe80::/10`)
  - Metadata endpoints (`169.254.169.254`)

**Connection strategy (practical for v1):**
- DNS resolution is for **validation only**
- httpx fetches by hostname normally (not by resolved IP)
- **Reduces risk** of DNS rebinding by:
  - Re-resolving and re-validating immediately before fetch (minimal TOCTOU window)
  - Disabling env proxies (`trust_env=False`)
  - Enforcing strict timeouts
- **Does NOT fully eliminate** TOCTOU rebinding attacks

**Non-goal for v1:** Pinning connection to resolved IP (requires custom Host header + SNI validation, complex)

### 5.4 Redirects

- Allow **at most 1 redirect**
- Allowed status codes: `301`, `302`, `303`, `307`, `308`

**Algorithm:**
```
1. First request with follow_redirects=False
2. If status in {301, 302, 303, 307, 308} and Location header present:
   a. Compute absolute redirect URL (handle relative Location)
   b. Validate redirect URL (scheme, host, userinfo, denylist, DNS)
   c. Second request to redirect URL
   d. If second response is also redirect → reject with E_IMAGE_FETCH_FAILED
3. Redirects count against the total 10s timeout budget
```

- Drop all headers from original request on redirect (no cookies/auth forwarded)
- Always issue `GET` for both requests

---

## 6. Upstream Fetch

### 6.1 HTTP Client

- Use `httpx.Client` (sync)
- Configuration:
  ```python
  httpx.Client(
      timeout=10.0,
      follow_redirects=False,
      trust_env=False,  # CRITICAL: ignore env proxies
  )
  ```
- Request headers:
  ```
  User-Agent: NexusImageProxy/1.0
  Accept: image/*,*/*;q=0.8
  ```
- Drop all other headers (no cookies, no auth forwarded)

### 6.2 Streaming + Size Enforcement

- Use streaming (`client.stream("GET", ...)`)
- Enforce:
  - **Max bytes:** 10 MB
  - Abort read immediately once limit exceeded
- If exceeded:
  - Raise `E_IMAGE_TOO_LARGE` (413)

---

## 7. Content Validation

### 7.1 MIME Type (Advisory)

- `Content-Type` header is a **hint**, not required
- **Immediate rejection** for clearly non-image types:
  - `text/html`, `text/plain`, `text/xml`
  - `application/json`, `application/javascript`
  - `image/svg+xml`
- **Proceed to sniff + Pillow** for:
  - Missing Content-Type
  - `application/octet-stream` (common misbehavior)
  - Any other ambiguous type

Many servers misbehave (e.g., serve images as `application/octet-stream`); requiring valid Content-Type would break legitimate images.

### 7.2 Magic-Byte Sniffing (Defense-in-Depth)

**Procedure:**
1. Read first 512 bytes
2. Strip leading ASCII whitespace (spaces, tabs, newlines)
3. Lowercase the result
4. Reject if starts with:
   - `<svg`
   - `<?xml`
   - `<html`
   - `<script`
   - `<!doctype`

This catches SVG/XML disguised with missing or wrong Content-Type.

### 7.3 Image Decoding (Pillow)

- Use **Pillow** to open and verify image
- **Decompression bomb protection:**
  ```python
  from PIL import Image
  import warnings

  # Set Pillow's built-in limit
  Image.MAX_IMAGE_PIXELS = 4096 * 4096  # 16 megapixels

  # Treat warnings as errors
  warnings.filterwarnings("error", category=Image.DecompressionBombWarning)

  try:
      img = Image.open(io.BytesIO(data))
      img.verify()  # Verify integrity without decoding pixels
  except (Image.DecompressionBombWarning, Image.DecompressionBombError):
      raise E_IMAGE_TOO_LARGE
  except Exception:
      raise E_INVALID_REQUEST
  ```
- Reject if Pillow cannot decode → `E_INVALID_REQUEST`
- No transformations performed; serve original bytes

### 7.4 Response Content-Type

**Source of truth for response `Content-Type`:**
1. If upstream sent valid `image/*` (not svg): use it
2. Else derive from Pillow format: `img.format.lower()` → `image/png`, `image/jpeg`, `image/gif`, `image/webp`
3. Never echo weird upstream types like `application/octet-stream`

---

## 8. Caching

### 8.1 Cache Model (v1)

- In-memory, per-process LRU cache (fine for uvicorn workers)
- Keyed by **normalized URL** (see §5.1)
- Value:
  - `bytes`
  - `content_type`
  - `etag = sha256(bytes)`

### 8.2 Limits

- Max entries: `64` (reduced from 256 to limit memory)
- **Max total bytes:** `128 MB` — evict LRU entries until under budget
- No TTL (eviction via LRU + byte budget)

**Rationale:** 64 entries × 10MB max = 640MB worst case, but most images are smaller. Byte budget caps actual memory.

### 8.3 ETag Format + Conditional GET

**ETag storage:**
- Store ETag as quoted string: `"<sha256_hex>"`
- Cache key maps to `(bytes, content_type, etag)`

**If-None-Match parsing:**
```python
def etags_match(if_none_match: str, cached_etag: str) -> bool:
    # Handle comma-separated values, strip W/ prefix and quotes
    for tag in if_none_match.split(","):
        tag = tag.strip()
        if tag.startswith("W/"):
            tag = tag[2:]
        tag = tag.strip('"')
        cached = cached_etag.strip('"')
        if tag == cached or tag == "*":
            return True
    return False
```

- If `etags_match(request_if_none_match, cached_etag)`:
  - Return `304 Not Modified` with no body
  - Include `ETag` header in response

### 8.4 Response Headers

Successful responses MUST include:

```
Cache-Control: private, max-age=86400
ETag: "<sha256_hex>"
Content-Type: image/<type>
```

**Note**: Use `private` (not `public`) because endpoint requires authentication. Shared caches should not store responses.

---

## 9. Integration with Sanitizer

- Sanitizer (PR-04) already rewrites:

  <img src="https://example.com/foo.png">
  ```
  →
  ```
  <img src="/media/image?url=https%3A%2F%2Fexample.com%2Ffoo.png">
  ```
- This PR makes those URLs resolvable
- No additional sanitizer changes required



---

## 10. Implementation Structure

### 10.1 Routes

**File:** `python/nexus/api/routes/media.py`

```python
@router.get("/media/image")
def get_proxied_image(
    url: str,
    request: Request,
    viewer: Annotated[Viewer, Depends(get_viewer)],  # auth enforcement only
) -> Response:
    # Check If-None-Match for conditional GET
    if_none_match = request.headers.get("If-None-Match")

    result = image_proxy.fetch_image(url, if_none_match=if_none_match)

    if result.not_modified:
        return Response(status_code=304, headers={"ETag": result.etag})

    return Response(
        content=result.data,
        media_type=result.content_type,
        headers={
            "Cache-Control": "private, max-age=86400",
            "ETag": result.etag,
        },
    )
```

**Note:** `viewer` dependency enforces auth; service does not need `db` or `viewer`.

---

### 10.2 Service

**New file:** `python/nexus/services/image_proxy.py`

**Primary entrypoint:**

```python
@dataclass
class ImageResponse:
    data: bytes
    content_type: str
    etag: str
    not_modified: bool = False

def fetch_image(url: str, if_none_match: str | None = None) -> ImageResponse:
    ...
```

**Responsibilities:**
- URL parsing + normalization
- Hostname denylist check
- DNS resolution + SSRF validation
- Fetch + streaming with size limit
- Content validation (sniff + Pillow decode)
- Cache lookup/store
- Conditional GET (If-None-Match → not_modified)
- Return bytes + content-type + etag

Routes must not contain logic.

### 10.3 Rate Limiting Hook (Future)

Image proxy can be abused as a bandwidth amplifier. Add a no-op hook for future rate limiting:

```python
def check_image_proxy_quota(viewer_id: UUID, bytes_fetched: int) -> None:
    """Hook for rate limiting. No-op in v1."""
    pass
```

Call after successful fetch. Enables per-user quotas later without refactor.

---

## 11. Tests

### 11.1 Test Dependencies

Add to dev dependencies:
- `respx` — mock httpx requests
- `pillow` — already needed for implementation

### 11.2 Test Fixtures

Include real image byte fixtures (not mock bytes):

```python
# tests/fixtures/images.py
# Minimal valid 1x1 PNG (67 bytes)
TINY_PNG = bytes([
    0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A,  # PNG signature
    # ... IHDR, IDAT, IEND chunks
])

# Use in tests to verify Pillow actually decodes
```

This ensures tests verify real Pillow decoding, not just mock pass-through.

### 11.3 Unit Tests (pytest)

**SSRF Tests (IP literals):**
- Blocks:
  - `http://127.0.0.1/foo.png`
  - `http://10.0.0.1/foo.png`
  - `http://169.254.169.254/latest/meta-data`
  - `http://example.com:1234/foo.png`
  - `file://...`
  - URLs with userinfo
- Allows valid public URL

**SSRF Tests (hostname → private IP via monkeypatch):**

respx mocks HTTP, not DNS. To test hostname→private IP blocking:

```python
def test_hostname_resolving_to_private_ip_is_blocked(monkeypatch):
    # Monkeypatch socket.getaddrinfo to return private IP
    def fake_getaddrinfo(host, port, *args, **kwargs):
        if host == "evil.test":
            return [(socket.AF_INET, socket.SOCK_STREAM, 0, "", ("127.0.0.1", 80))]
        return original_getaddrinfo(host, port, *args, **kwargs)

    monkeypatch.setattr(socket, "getaddrinfo", fake_getaddrinfo)

    with pytest.raises(SsrfBlockedError):
        fetch_image("http://evil.test/image.png")
```

**Hostname Denylist Tests:**
- `http://localhost/foo.png` → blocked
- `http://internal.local/foo.png` → blocked
- `http://service.internal/foo.png` → blocked

**Redirect Tests:**
- One redirect allowed
- Second redirect rejected
- Redirect to private IP rejected
- Redirect to denylist hostname rejected

**Content Tests:**
- Reject SVG (via Content-Type and via sniff)
- Reject `<?xml` payload even with image/png header
- Reject oversized payload (>10MB) → `E_IMAGE_TOO_LARGE`
- Reject oversized dimensions (>4096x4096) → `E_IMAGE_TOO_LARGE`
- Accept valid PNG/JPEG

---

### 11.4 Integration Tests

- Mock upstream image via respx with real PNG fixture bytes
- Request `/media/image?url=...` with auth (use `params={"url": ...}` for encoding)
- Assert:
  - 200 OK
  - Correct headers (`Cache-Control: private`, `ETag` quoted)
  - Body matches upstream
  - Content-Type is valid image type
- Repeat request with same URL:
  - Verify served from cache (no upstream call via respx)
- Repeat request with `If-None-Match: "<etag>"`:
  - Verify 304 Not Modified

**Error code tests:**
- Oversized image → 413 with `E_IMAGE_TOO_LARGE`
- Private IP → 403 with `E_SSRF_BLOCKED`
- Timeout → 504 with `E_INGEST_TIMEOUT`

---

## 12. Dependencies

Add to `python/pyproject.toml`:

```toml
dependencies = [
    # ... existing ...
    "pillow>=10.0.0",
]

[project.optional-dependencies]
dev = [
    # ... existing ...
    "respx>=0.20.0",
]
```

---

## 13. Done Definition

PR-05 is complete when:
- Images in sanitized web articles load successfully
- SSRF vectors are blocked with explicit tests (including DNS monkeypatch)
- Hostname denylist rejects localhost, .local, .internal
- Cache works deterministically (LRU, 64 entries, 128MB budget)
- Conditional GET returns 304 when ETag matches (with proper quote handling)
- Error codes return correct HTTP status (413 for too large, 403 for SSRF, 504 for timeout)
- Content-Type derived correctly (upstream if valid image/*, else from Pillow format)
- No unauthenticated access is possible
- Tests use real PNG fixture bytes (not mock pass-through)
- All tests pass (backend + existing suites remain green)

